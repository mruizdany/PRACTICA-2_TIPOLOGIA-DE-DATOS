---
title: 'PRACTICA2: Analisis de accidentes de transito en BogotÃ¡'
author: "Autor: Daniel Leonardo Martinez Ruiz"
date: "Enero 2025"
output:
  html_document:
    theme: cosmo
    toc: yes
    toc_depth: 2

---

# 'PRACTICA 2: AnÃ¡lisis de accidentes de transito en BogotÃ¡'

## IntroducciÃ³n

Los accidentes de trÃ¡nsito constituyen un grave problema de salud
pÃºblica a nivel mundial, causando un nÃºmero significativo de muertes y
lesiones cada aÃ±o. En ciudades como BogotÃ¡, la creciente motorizaciÃ³n y
la urbanizaciÃ³n han exacerbado esta problemÃ¡tica, generando una
necesidad urgente de implementar medidas para mejorar la seguridad vial.

## Objetivos EspecifÃ­cos

El presente estudio tiene como objetivo principal identificar los
factores de riesgo asociados a los accidentes de trÃ¡nsito en BogotÃ¡ y
localizar las zonas de mayor vulnerabilidad en la ciudad.

A travÃ©s del anÃ¡lisis de un conjunto de datos detallados sobre
accidentes de trÃ¡nsito, se busca contribuir al conocimiento sobre las
causas de los siniestros viales y proporcionar informaciÃ³n valiosa para
la toma de decisiones en materia de seguridad vial.

Objetivos EspecÃ­ficos:

-   Identificar las caracterÃ­sticas de los vehÃ­culos, conductores y vÃ­as
    involucradas en los accidentes con mayor frecuencia.

-   Evaluar la relaciÃ³n entre la gravedad de los accidentes y factores
    como la hora del dÃ­a, el dÃ­a de la semana y las condiciones
    climÃ¡ticas.

-   Localizar los puntos negros de accidentalidad en la ciudad.

-   Proponer recomendaciones para mejorar la seguridad vial en BogotÃ¡.

Este estudio se centrarÃ¡ en el anÃ¡lisis de datos de accidentes de
trÃ¡nsito ocurridos en BogotÃ¡ durante el perÃ­odo comprendido en el
aÃ±o2023. El Ã¡rea de estudio se limitarÃ¡ al territorio urbano de la
ciudad.

## JustificaciÃ³n

Comprender las causas de los accidentes de trÃ¡nsito es fundamental para
diseÃ±ar e implementar estrategias efectivas de prevenciÃ³n. Los
resultados de este estudio permitirÃ¡n identificar las Ã¡reas prioritarias
para la intervenciÃ³n, optimizar el uso de los recursos y reducir el
nÃºmero de vÃ­ctimas de accidentes de trÃ¡nsito en BogotÃ¡.

#### Estructura del Documento

En las siguientes secciones se presentarÃ¡ el marco teÃ³rico, los
materiales y mÃ©todos utilizados, los resultados obtenidos y una
discusiÃ³n de los hallazgos. Finalmente, se presentarÃ¡n las conclusiones
y recomendaciones para futuras investigaciones.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r setup, include=FALSE}
# Limpiar el Environment
remove(list=ls())

# Cargar el paquete task Chedule
install.packages("taskscheduleR", dependencies = TRUE)

# Instalar paquetes (si fuera necesario). Comentar estas lÃ­neas tras la primera instalaciÃ³n 
install.packages("dbscan")
install.packages(c("rpart", "rpart.plot", "caret"))
install.packages("skimr")
install.packages("janitor")
install.packages("gt")
install.packages("randomForest")

# ---- Carga de librerÃ­as ----
library(readxl)
library(readr)
library(dplyr)
library(tidyr)
library(janitor)
library(ggplot2)
library(gt)
library(lubridate)
library(cluster)
library(factoextra)
library(scales)
library(dbscan)
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(skimr)   

```

```{r setup, include=FALSE}

# Ruta del directorio de trabajo
getwd()


# Definir el usuario y directorios
user_daniel = Sys.getenv("OneDrive")
user_daniel = gsub ("\\\\", "/", user_daniel)

direccion1 = paste(user_daniel,"/Documents/tipologia de datos/data", sep = "")
direccion2 = paste(user_daniel,"/Documents/tipologia de datos/out", sep = "")

# Direccionar el directorio de trabajo
setwd(direccion1)

# Lamar a las bases de datos
siniestros <- read.csv("Siniestros.csv", sep = ";", stringsAsFactors = FALSE)
vehiculos <- read.csv("Vehiculos.csv", sep = ";", stringsAsFactors = FALSE)
actor_vial <- read.csv("Actor_vial.csv", sep = ";", stringsAsFactors = FALSE)


# ExploraciÃ³n inicial
head(siniestros)
head(vehiculos)
head(actor_vial)
```

## MetodologÃ­a y tratamiento de los datos

### DescripciÃ³n de las variables

La siguiente tabla presenta una descripciÃ³n detallada de las variables
utilizadas en este estudio. Cada variable se clasifica segÃºn su tipo
(numÃ©rica, categÃ³rica, ordinal) y se describe su significado e
importancia para el anÃ¡lisis.

Las variables espaciales (longitud y latitud) permiten realizar anÃ¡lisis
geogrÃ¡ficos para identificar patrones espaciales en la ocurrencia de
accidentes.

Las variables relacionadas con los vehÃ­culos y los actores viales
proporcionan informaciÃ³n sobre las caracterÃ­sticas de los vehÃ­culos
involucrados y las personas afectadas.

Finalmente, las variables de identificaciÃ³n permiten relacionar los
diferentes registros y realizar un anÃ¡lisis mÃ¡s completo.

```{r setup, include=FALSE}

# Crear un data frame con la informaciÃ³n de las variables
variables <- data.frame(
  Variable = c("Fecha_Acc", "Hora_Accidente", "Dia_Semana_Acc", "Longitud", "Latitud", "Direccion", "Zona", "Clase", "Servicio", "Sistema_Transporte", "Rol_Actor", "Condicion", "Edad", "Genero", "Codigo_Accidente", "Codigo_Vehiculo", "Codigo_Accidentado", "Condicion_Climatica", "Estado_Via", "Tipo_Siniestro"),
  Tipo = c("CategÃ³rica (Fecha)", "Continua", "CategÃ³rica Ordinal", "Continua", "Continua", "Descriptiva", "CategÃ³rica", "CategÃ³rica", "CategÃ³rica", "Binaria", "CategÃ³rica", "CategÃ³rica Ordinal", "Continua", "CategÃ³rica", "Nominal", "Nominal", "Nominal", "Categorical", "Categorical", "Categorical"),
  DescripciÃ³n = c(
    "Fecha exacta del accidente",
    "Hora del dÃ­a en que ocurriÃ³ el siniestro",
    "DÃ­a de la semana en que ocurriÃ³ el accidente",
    "Coordenada geogrÃ¡fica que indica la distancia en grados decimales con respecto al meridiano principal",
    "Coordenada geogrÃ¡fica que indica la distancia en grados decimales con respecto a la lÃ­nea del Ecuador",
    "DirecciÃ³n completa donde ocurriÃ³ el siniestro vial",
    "Barrio o zona de siniestro",
    "Tipo de vehÃ­culo involucrado",
    "Clase de servicio proporcionado por el vehÃ­culo",
    "Indica si el vehÃ­culo pertenece a un sistema de transporte integrado como SITP",
    "Rol del actor vial en el accidente",
    "Resultado del accidente para el actor vial",
    "Edad del actor vial en aÃ±os",
    "GÃ©nero del actor vial",
    "Identificador Ãºnico del accidente",
    "Identificador Ãºnico del vehÃ­culo",
    "Identificador Ãºnico del actor vial",
    "Condiciones climÃ¡ticas al momento del accidente",
    "Estado de la vÃ­a al momento del accidente",
    "Tipo de siniestro"
  ),
  Importancia = c(
    "Permite analizar patrones temporales",
    "Identificar alta de accidentabilidad durante el dÃ­a",
    "Ayuda a identificar dÃ­as con mayor incidencia",
    "AnÃ¡lisis geoespacial",
    "AnÃ¡lisis geoespacial",
    "UbicaciÃ³n especÃ­fica",
    "AnÃ¡lisis zonal",
    "CaracterÃ­sticas del vehÃ­culo",
    "Tipo de servicio",
    "IdentificaciÃ³n de transporte pÃºblico",
    "Rol en el accidente",
    "Gravedad del accidente",
    "Grupos vulnerables",
    "Diferencias de gÃ©nero",
    "Unir tablas",
    "Unir tablas",
    "Unir tablas",
    "Condiciones ambientales",
    "Estado de la vÃ­a",
    "Tipo de siniestro"
  )
)

# Especificar la ruta para guardar el archivo CSV
direccion2 = paste(user_daniel,"/Documents/tipologia de datos/out", sep = "")

setwd(direccion2)

out_file <- file.path(direccion2, "variables.csv")

# Guardar el data frame como archivo CSV

write.csv(variables, file = out_file, row.names = FALSE)

# ConfirmaciÃ³n de que se ha guardado correctamente
cat("Archivo CSV guardado en: ", out_file)

```

        
1)   Variables espaciales: Estas variables son fundamentales para identificar zonas de alto riesgo y diseÃ±ar intervenciones especÃ­ficas para cada Ã¡rea.
2)   Variables de vehÃ­culos: Al analizar las caracterÃ­sticas de los vehÃ­culos involucrados, podemos identificar los tipos de vehÃ­culos mÃ¡s propensos a estar involucrados en accidentes y diseÃ±ar polÃ­ticas de seguridad vial especÃ­ficas para cada tipo de vehÃ­culo.
3)   Variables de actores viales: Al analizar las caracterÃ­sticas de los conductores, pasajeros y peatones, podemos identificar los grupos mÃ¡s vulnerables y diseÃ±ar programas de educaciÃ³n vial y prevenciÃ³n de accidentes dirigidos a estos grupos.
4)   Variables de contexto: Las variables relacionadas con las condiciones climÃ¡ticas y el estado de la vÃ­a permiten evaluar el impacto de estos factores en la ocurrencia de accidentes.

### Limpeza del dataset

Una vez identificadas las variables y sus caracterÃ­sticas, el siguiente
paso consiste en la limpieza de los datos. Este proceso es esencial para
asegurar que el dataset sea adecuado para el anÃ¡lisis posterior, ya que
los datos crudos pueden contener valores faltantes, inconsistencias o
registros irrelevantes que podrÃ­an afectar los resultados. Por lo tanto,
debemos plantearnos cÃ³mo modificar el dataset de manera efectiva.

La clave de una limpieza de datos eficiente radica en elegir el conjunto
de procedimientos adecuados segÃºn las caracterÃ­sticas especÃ­ficas de la
base de datos. Dependiendo de la naturaleza de las variables y los
problemas detectados, podemos optar por tÃ©cnicas como la imputaciÃ³n de
valores faltantes, la correcciÃ³n de valores atÃ­picos, la conversiÃ³n de formatos de datos o la eliminaciÃ³n de columnas innecesarias.

Se debe considerar, tanto la integridad como la precisiÃ³n de la
informaciÃ³n, con el objetivo de obtener datos limpios que faciliten una
interpretaciÃ³n clara y precisa durante el anÃ¡lisis.

Dado la complejidad del dataset, dicidi hacer la limpieza en varias fases: 

La fase 1, consiste en hacer una limpieza muy basica buscando los valores nulos y eliminarlos. TambiÃ©n, se calculo el promedio para aquellas filas faltantes pero que no era calido la eliminaicÃ³n de la fila completa ya que se considera que el dato es importante. Tambien se detectaron algunos outliers y se hizo el tratamiento mediante el metodo z-scores que permite ver comportamientos de las variables vecinas y asi imputar un dato con mucha presiciÃ³n. 

La fase 2, consiste en unir todos los dataset que se dispone del estudio de los accidentes de BogotÃ¡ en el aÃ±o 2023, con el objetivo de tener la base de datos optimizada poder hacer una limpieza  detallada y no tener posteriormente comportameintos erroneos con el analisis de los datos

fase 3, Una vez que tenemos el dataset consolidado, vamos a realizar varias tareas de limpieza para preparar los datos para su anÃ¡lisis: Eliminar columnas vacÃ­as: Esto se hace para asegurarnos de que no estamos trabajando con columnas que no aportan informaciÃ³n. Renombrar columnas: Utilizamos la funciÃ³n clean_names() para asegurar que los nombres de las columnas sean legibles y no contengan espacios. Convertir variables de tipo texto (caracteres) en factores: Esto es Ãºtil para anÃ¡lisis de datos categÃ³ricos.



```{r setup, include=FALSE}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ ConsolidaciÃ³n del dataset
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Unir datasets en uno solo para facilitar la limpieza
siniestros_consolidado <- siniestros %>%
  inner_join(vehiculos %>% distinct(Codigo_Accidente, .keep_all = TRUE), by = "Codigo_Accidente") %>%
  inner_join(actor_vial %>% distinct(Codigo_Accidente, .keep_all = TRUE), by = "Codigo_Accidente")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Limpieza y NormalizaciÃ³n
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

limpiar_datos <- function(dataset) {
  dataset %>%
    select(where(~ !all(is.na(.)))) %>%  # Eliminar columnas completamente vacÃ­as
    clean_names() %>%  # Renombrar columnas para evitar problemas con espacios
    mutate(across(where(is.character), as.factor))  # Convertir caracteres a factores
}

detectar_outliers <- function(x) {
  z_scores <- scale(x)
  outliers <- which(abs(z_scores) > 3)
  if(length(outliers) > 0 && length(outliers) < length(x)) {
    x[outliers] <- max(x[-outliers], na.rm = TRUE)
  }
  return(x)
}

gestionar_na <- function(dataset) {
  dataset %>%
    mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))
}

# Aplicamos la limpieza y normalizaciÃ³n directamente sobre siniestros_consolidado
siniestros_limpio <- siniestros_consolidado %>%
  limpiar_datos() %>%
  mutate(across(where(is.numeric), detectar_outliers)) %>%
  gestionar_na()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ Guardado del Dataset Limpio
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Definir ruta de salida
direccion_out <- file.path(user_daniel, "/Documents/tipologia de datos/out")
ruta_salida <- file.path(direccion_out, "siniestros_limpio.csv")

# Guardar dataset limpio
write.csv(siniestros_limpio, file = ruta_salida, row.names = FALSE)

# ConfirmaciÃ³n
cat("Archivo CSV guardado en:", ruta_salida)


``` 

## Analisis de los datos detallada 

### 1.  Modelo No Supervisado: DBSCAN

```{r setup, include=FALSE}

# Cargar librerÃ­as necesarias
library(dbscan)
library(factoextra)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Cargar el Dataset desde "out"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Definir la ruta del archivo en la carpeta "out"
direccion_out <- file.path(user_daniel, "Documents/tipologia de datos/out")
ruta_siniestros <- file.path(direccion_out, "siniestros_limpio.csv")

# Verificar si el archivo existe antes de leerlo
if (file.exists(ruta_siniestros)) {
  siniestros_final <- read_csv(ruta_siniestros)
  cat("Archivo cargado correctamente desde:", ruta_siniestros, "\n")
} else {
  stop("Error: No se encontrÃ³ el archivo 'siniestros_limpio.csv' en la carpeta 'out/'.")
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ PreparaciÃ³n de datos numÃ©ricos
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Seleccionar solo variables numÃ©ricas
datos_numericos <- siniestros_final %>%
  select(where(is.numeric))

# Eliminar filas con NA, NaN o Inf
datos_numericos <- datos_numericos %>%
  filter_all(all_vars(!is.na(.) & !is.nan(.) & !is.infinite(.)))

# Normalizar los datos
datos_norm <- scale(datos_numericos)

# Convertir los datos a una matriz numÃ©rica
datos_norm <- as.matrix(datos_norm)

# Asegurarse de que no haya NA, NaN o Inf despuÃ©s de la normalizaciÃ³n
datos_norm <- datos_norm[complete.cases(datos_norm), ]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ Ajustar parÃ¡metro k en kNNdistplot
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Verificar el tamaÃ±o de los datos
n_filas <- nrow(datos_norm)

# Ajustar k si el nÃºmero de filas es menor que 5
k_value <- min(5, n_filas - 1)  # Aseguramos que k no sea mayor que el nÃºmero de filas

# Determinar epsilon Ã³ptimo usando el grÃ¡fico de k-distancias
kNNdistplot(datos_norm, k = k_value)
abline(h = 1.5, col = "red", lty = 2) # Ajustar el valor Ã³ptimo manualmente

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£ Aplicar DBSCAN para agrupamiento
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ajustar DBSCAN con los parÃ¡metros adecuados
dbscan_result <- dbscan(datos_norm, eps = 1.5, minPts = 5)
siniestros_final$cluster_dbscan <- as.factor(dbscan_result$cluster)

# Guardar el dataset con clusters en "out"
write.csv(siniestros_final, "out/siniestros_clusterizado_dbscan.csv", row.names = FALSE)

# Visualizar los clusters DBSCAN
fviz_cluster(list(data = datos_norm, cluster = dbscan_result$cluster)) +
  ggsave("out/dbscan_clusters.png")




```



### 2. AnÃ¡lisis Supervisado: Random Forest
```{r setup, include=FALSE}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Cargar el Dataset desde "out"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Definir la ruta del archivo en la carpeta "out"
direccion_out <- file.path(user_daniel, "Documents/tipologia de datos/out")
ruta_siniestros <- file.path(direccion_out, "siniestros_limpio.csv")

# Verificar si el archivo existe antes de leerlo
if (file.exists(ruta_siniestros)) {
  siniestros_final <- read_csv(ruta_siniestros)
  cat("Archivo cargado correctamente desde:", ruta_siniestros, "\n")
} else {
  stop("Error: No se encontrÃ³ el archivo 'siniestros_limpio.csv' en la carpeta 'out/'.")
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ï¸âƒ£ Crear variable de franja horaria
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

siniestros_final <- siniestros_final %>%
  mutate(franja_horaria = case_when(
    Hora_Acc >= 0 & Hora_Acc < 6 ~ "Madrugada",
    Hora_Acc >= 6 & Hora_Acc < 12 ~ "MaÃ±ana",
    Hora_Acc >= 12 & Hora_Acc < 18 ~ "Tarde",
    Hora_Acc >= 18 & Hora_Acc <= 23 ~ "Noche"
  ))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2ï¸âƒ£ Seleccionar variables predictoras
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Seleccionar las columnas necesarias para el modelo
datos_modelo <- siniestros_final %>%
  select(Longitud, Latitud, franja_horaria)

# ConversiÃ³n a factor
datos_modelo$franja_horaria <- as.factor(datos_modelo$franja_horaria)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3ï¸âƒ£ DivisiÃ³n en conjunto de entrenamiento y prueba
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

set.seed(123)
indices <- createDataPartition(datos_modelo$franja_horaria, p = 0.8, list = FALSE)
datos_entrenamiento <- datos_modelo[indices, ]
datos_test <- datos_modelo[-indices, ]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4ï¸âƒ£ Entrenar el modelo Random Forest
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

modelo_rf <- randomForest(franja_horaria ~ Longitud + Latitud, 
                          data = datos_entrenamiento, 
                          ntree = 500, 
                          importance = TRUE)

# Predicciones
predicciones_rf <- predict(modelo_rf, datos_test)

# EvaluaciÃ³n del modelo
conf_matrix_rf <- confusionMatrix(predicciones_rf, datos_test$franja_horaria)
print(conf_matrix_rf)

# Guardar matriz de confusiÃ³n
write.csv(conf_matrix_rf$table, "out/matriz_confusion_rf.csv")

# Guardar grÃ¡fico de importancia de variables
pdf("out/importancia_variables_rf.pdf")
varImpPlot(modelo_rf, main = "Importancia de Variables - Random Forest")
dev.off()

```

### ConclusiÃ³n
Se realizaron anÃ¡lisis no supervisados (K-Means, K-Medoids y DBSCAN) para segmentar los siniestros. Luego, se aplicaron modelos supervisados (Random Forest y Ãrbol de DecisiÃ³n) para predecir franjas horarias. Se generaron visualizaciones y resultados que se guardaron en la carpeta `out/`. ğŸš€



